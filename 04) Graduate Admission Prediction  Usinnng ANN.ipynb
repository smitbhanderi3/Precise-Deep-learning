{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506e5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffd26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36bcff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12a83db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75574aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e10dbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233aabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5deaaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03a3009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400045e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1db16dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c818d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce4eddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91b29933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from  tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ce43c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "#hidden Layer\n",
    "model.add(Dense(7,activation=\"relu\",input_dim=7))\n",
    "model.add(Dense(7,activation=\"relu\"))\n",
    "#output layer \n",
    "model.add(Dense(1,activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81a97e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a10f4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=\"Adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97268036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1165 - val_loss: 0.1126\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0819 - val_loss: 0.0787\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.0555\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0390 - val_loss: 0.0403\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0291 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0235 - val_loss: 0.0274\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0214 - val_loss: 0.0253\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0243\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0237\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0196 - val_loss: 0.0232\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0192 - val_loss: 0.0227\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0223\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0212\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0176 - val_loss: 0.0208\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0204\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0201\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0198\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0194\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0190\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0186\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0183\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0154 - val_loss: 0.0180\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0151 - val_loss: 0.0176\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0173\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0169\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0152\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0074\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e2dff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15b58f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26acaaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055329628111259"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a49a6cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bc12c6f3a0>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a16f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
